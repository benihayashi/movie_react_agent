{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import re\n",
    "import chromadb\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>showname</th>\n",
       "      <th>first_airing</th>\n",
       "      <th>imdb</th>\n",
       "      <th>lang</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Allo 'Allo!</td>\n",
       "      <td>1982-12-30</td>\n",
       "      <td>tt0086659</td>\n",
       "      <td>English</td>\n",
       "      <td>&lt;p&gt;In this spoof of World War II, René Artois ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Orrible</td>\n",
       "      <td>2001-09-10</td>\n",
       "      <td>tt0299233</td>\n",
       "      <td>English</td>\n",
       "      <td>&lt;p&gt;Paul Clark is a cab driver and wannabe smal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Run Sbit</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>None</td>\n",
       "      <td>Welsh</td>\n",
       "      <td>&lt;p&gt;Satirical comedy series in a fly on the wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Til Death Do Us Part</td>\n",
       "      <td>2007-03-19</td>\n",
       "      <td>None</td>\n",
       "      <td>English</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;'Til Death Do Us Part&lt;/b&gt; is murder-myst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Til Death Do Us Part</td>\n",
       "      <td>2019-07-09</td>\n",
       "      <td>tt10553838</td>\n",
       "      <td>English</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;'Til Death Do Us Part&lt;/b&gt; follows lovers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A Hundred Year's Inheritance</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>tt5679588</td>\n",
       "      <td>Korean</td>\n",
       "      <td>&lt;p&gt;A warm-hearted family drama about a long-ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Impostora</td>\n",
       "      <td>2016-09-04</td>\n",
       "      <td>tt5187234</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>&lt;p&gt;The story of Two twins sisters. One was rap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A Killer's Mistake</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>tt11611382</td>\n",
       "      <td>English</td>\n",
       "      <td>&lt;p&gt;Ten iconic and international murder stories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>A Kind of Living</td>\n",
       "      <td>1988-02-19</td>\n",
       "      <td>tt0282308</td>\n",
       "      <td>English</td>\n",
       "      <td>&lt;p&gt;A late '80s British comedy about a married ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A Life Time Love</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>tt6035380</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>&lt;p&gt;The story takes place in a mythological wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        showname first_airing        imdb        lang  \\\n",
       "0                   'Allo 'Allo!   1982-12-30   tt0086659     English   \n",
       "1                       'Orrible   2001-09-10   tt0299233     English   \n",
       "2                      'Run Sbit   2016-04-01        None       Welsh   \n",
       "3          'Til Death Do Us Part   2007-03-19        None     English   \n",
       "4          'Til Death Do Us Part   2019-07-09  tt10553838     English   \n",
       "..                           ...          ...         ...         ...   \n",
       "95  A Hundred Year's Inheritance   2013-01-05   tt5679588      Korean   \n",
       "96                   A Impostora   2016-09-04   tt5187234  Portuguese   \n",
       "97            A Killer's Mistake   2018-10-02  tt11611382     English   \n",
       "98              A Kind of Living   1988-02-19   tt0282308     English   \n",
       "99              A Life Time Love   2017-06-12   tt6035380     Chinese   \n",
       "\n",
       "                                          description  \n",
       "0   <p>In this spoof of World War II, René Artois ...  \n",
       "1   <p>Paul Clark is a cab driver and wannabe smal...  \n",
       "2   <p>Satirical comedy series in a fly on the wal...  \n",
       "3   <p><b>'Til Death Do Us Part</b> is murder-myst...  \n",
       "4   <p><b>'Til Death Do Us Part</b> follows lovers...  \n",
       "..                                                ...  \n",
       "95  <p>A warm-hearted family drama about a long-ru...  \n",
       "96  <p>The story of Two twins sisters. One was rap...  \n",
       "97  <p>Ten iconic and international murder stories...  \n",
       "98  <p>A late '80s British comedy about a married ...  \n",
       "99  <p>The story takes place in a mythological wor...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['showname','first_airing','imdb','lang','description']\n",
    "def fetch_rows(limit: int, offset: int):\n",
    "    conn = sqlite3.connect(\"movie_db.sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "    executor = cursor.execute(f'select {\",\".join(cols)} from tvmaze where metadata is null and description is not null order by showname asc limit {limit} offset {offset}')\n",
    "    data = executor.fetchall()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return data\n",
    "\n",
    "pd.DataFrame(fetch_rows(100, 0), columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a ChatOpenAI model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.getenv('OPENAI_KEY'),\n",
    "    # model=\"deepseek-r1-distill-llama-8b\",\n",
    "    # openai_api_base='http://127.0.0.1:1234/v1',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools for extracting metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(values: list[str]):\n",
    "    with open(f'./prompts/movie_metadata_extraction.txt', 'r') as file:\n",
    "        data = file.read().rstrip()\n",
    "        index=0\n",
    "            \n",
    "        while(data.find(f\"!<INPUT_{index}>\") > 0):\n",
    "            data = data.replace(f\"!<INPUT_{index}>\", values[index] if len(values) > index is not None else '')\n",
    "            index+=1\n",
    "        return data\n",
    "\n",
    "    return None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define job to process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def process_job(limit: int, offset: int) -> list[dict]:\n",
    "    results = []\n",
    "    completed = 0\n",
    "    data = fetch_rows(limit, offset)\n",
    "    for row in data:\n",
    "        if(row[4] is not None and len(row[4]) > 0):\n",
    "            prompt = generate_prompt([row[4]])\n",
    "            output = llm.invoke([HumanMessage(content=prompt)])\n",
    "            json_str = re.findall(r\"```json(.*?)```\", output.text(),re.DOTALL)\n",
    "            if(len(json_str) > 0):\n",
    "                try:\n",
    "                    structured_data = json.loads(json_str[0])\n",
    "                    conn = sqlite3.connect(\"movie_db.sqlite\")\n",
    "                    cursor = conn.cursor()\n",
    "                    showname:str = row[0].replace(\"'\", \"\\\\'\")\n",
    "                    cursor.execute(f'update tvmaze set metadata = \\'{json.dumps(structured_data)}\\' where showname = \\'{showname}\\'')\n",
    "                    conn.commit()\n",
    "                    cursor.close()\n",
    "                    conn.close()\n",
    "                    results.append(structured_data)\n",
    "                except Exception  as e:\n",
    "                    # print(row[0])\n",
    "                    # print(e)\n",
    "                    pass\n",
    "            completed+=1\n",
    "            clear_output(wait=True)\n",
    "            print(f\"{completed}/{limit} done ({round(completed/limit, 2) * 100}%)\")\n",
    "            \n",
    "    return results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/2000 done (8.0%)\n"
     ]
    }
   ],
   "source": [
    "results = process_job(2000,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define tools for vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"fake\", base_url='http://127.0.0.1:1234/v1')\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")  \n",
    "collection = chroma_client.get_or_create_collection(name=\"movies\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(model=\"text-embedding-nomic-embed-text-v1.5\", input=text)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def db_to_embeddings(limit: int, offset: int):\n",
    "    cols = ['showname','first_airing','imdb','lang','description', 'metadata']\n",
    "    conn = sqlite3.connect(\"movie_db.sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "    executor = cursor.execute(f'select {\",\".join(cols)} from tvmaze where metadata is not null and processed is null order by showname asc limit {limit} offset {offset}')\n",
    "    rows = executor.fetchall()\n",
    "\n",
    "    \n",
    "    for row in rows:\n",
    "        title = row[0]\n",
    "        description=  row[4]\n",
    "        id = f\"{title}-{row[2]}\"\n",
    "        text = f\"{title} {description}\" \n",
    "        language = row[3] \n",
    "\n",
    "        embedding = get_embedding(text)\n",
    "        metadata : dict = json.loads(row[5])\n",
    "        parsed_metadata: dict = {}\n",
    "        \n",
    "        for key in metadata.keys():\n",
    "            if(len(metadata[key]) == 0):\n",
    "                continue\n",
    "            parsed_metadata[key] = ','.join(metadata[key])\n",
    "\n",
    "        parsed_metadata[\"title\"] = title if title is not None else ''\n",
    "        parsed_metadata[\"language\"] = language if language is not None else ''\n",
    "        parsed_metadata[\"aired\"] = row[1] if row[1] is not None else ''\n",
    "        print(parsed_metadata)\n",
    "      \n",
    "        collection.add(\n",
    "            ids=[id],\n",
    "            embeddings=[embedding],\n",
    "            metadatas=[parsed_metadata]\n",
    "        )\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        executor = cursor.execute(f'update tvmaze set processed = true where showname = \\'{title}\\'')\n",
    "        conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 3B no Koibito-None\n",
      "Insert of existing embedding ID: 3B no Koibito-None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'characters': 'Kobayashi Haruka,Shintaro,Yu,Yoshi', 'genre': 'romance,drama', 'title': '3B no Koibito', 'language': 'Japanese', 'aired': '2021-01-09'}\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdb_to_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[69], line 45\u001b[0m, in \u001b[0;36mdb_to_embeddings\u001b[1;34m(limit, offset)\u001b[0m\n\u001b[0;32m     38\u001b[0m     collection\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m     39\u001b[0m         ids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mid\u001b[39m],\n\u001b[0;32m     40\u001b[0m         embeddings\u001b[38;5;241m=\u001b[39m[embedding],\n\u001b[0;32m     41\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39m[parsed_metadata]\n\u001b[0;32m     42\u001b[0m     )\n\u001b[0;32m     44\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m---> 45\u001b[0m     executor \u001b[38;5;241m=\u001b[39m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupdate tvmaze set processed = true where showname = \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtitle\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     47\u001b[0m cursor\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "db_to_embeddings(10,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 1000 Years of History | Language: English\n",
      "Title: 12 Monkeys | Language: English\n",
      "Title: 14 - Diaries of the Great War | Language: French\n",
      "Title: 1066: A Year to Conquer England | Language: English\n",
      "Title: 11.22.63 | Language: English\n"
     ]
    }
   ],
   "source": [
    "query_text = \"movies about history\"\n",
    "query_embedding = get_embedding(query_text)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "for movie in results[\"metadatas\"][0]:\n",
    "    print(f\"Title: {movie['title']} | Language: {movie['language']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
